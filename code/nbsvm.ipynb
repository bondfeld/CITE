{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, grams):\n",
    "    words = sentence.split()\n",
    "    tokens = []\n",
    "    for gram in grams:\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            tokens += [\"_*_\".join(words[i:i+gram])]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_text(df, pos_txt, neg_txt):\n",
    "    for i in range(df.shape[0]):\n",
    "        if(df.loc[i,'label'] == 0):    \n",
    "            with open(neg_txt, 'a') as file:\n",
    "                file.writelines(df.loc[i,'txt'] + \"\\n\")\n",
    "\n",
    "        if(df.loc[i,'label'] == 1):   \n",
    "            with open(pos_txt, 'a') as file:\n",
    "                file.writelines(df.loc[i,'txt'] + \"\\n\")\n",
    "\n",
    "    \n",
    "    return pos_txt, neg_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(f, grams):\n",
    "    dic = Counter()\n",
    "    i = 0\n",
    "    for sentence in open(f).readlines():\n",
    "        dic.update(tokenize(sentence, grams))\n",
    "        if(i < 30):\n",
    "            print(tokenize(sentence, grams))\n",
    "            i = i + 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file_pos, file_neg, dic, r, outfn, grams):\n",
    "    output = []\n",
    "    for beg_line, f in zip([\"1\", \"-1\"], [file_pos, file_neg]):\n",
    "        for l in open(f).readlines():\n",
    "            tokens = tokenize(l, grams)\n",
    "            indexes = []\n",
    "            for t in tokens:\n",
    "                try:\n",
    "                    indexes += [dic[t]]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            indexes = list(set(indexes))\n",
    "            indexes.sort()\n",
    "            line = [beg_line]\n",
    "            for i in indexes:\n",
    "                line += [\"%i:%f\" % (i + 1, r[i])]\n",
    "            output += [\" \".join(line)]\n",
    "    output = \"\\n\".join(output)\n",
    "    f = open(outfn, \"w\")\n",
    "    f.writelines(output)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratio(poscounts, negcounts, alpha=1):\n",
    "    alltokens = list(set(list(poscounts.keys()) + list(negcounts.keys())))\n",
    "    dic = dict((t, i) for i, t in enumerate(alltokens))\n",
    "    d = len(dic)\n",
    "    print(\"computing r...\",d)\n",
    "    p, q = np.ones(d) * alpha , np.ones(d) * alpha\n",
    "    i = 0\n",
    "    for t in alltokens:\n",
    "        p[dic[t]] += poscounts[t]\n",
    "        q[dic[t]] += negcounts[t]\n",
    "        p /= abs(p).sum()\n",
    "        q /= abs(q).sum()\n",
    "        rt = np.log(p/q)\n",
    "        if(i < 30):\n",
    "            print(t, max(p), p)\n",
    "            print(t,q, max(q))\n",
    "        i = i + 1\n",
    "        \n",
    "    p /= abs(p).sum()\n",
    "    q /= abs(q).sum()\n",
    "    r = np.log(p/q)\n",
    "    return dic, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", error_bad_lines=False)\n",
    "csv_text(df,\"test-true.txt\", \"test-falseg.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptrain = \"train-true.txt\"\n",
    "ntrain = \"train-false.txt\"\n",
    "ptest = \"test-true.txt\"\n",
    "ntest = \"test-false.txt\"\n",
    "liblinear = \"liblinear-1.96\"\n",
    "out = \"TEST-SCORE\"\n",
    "ngram = \"2\"\n",
    "ngram = [int(i) for i in ngram]\n",
    "print(\"counting...\")\n",
    "\n",
    "poscounts = build_dict(ptrain, ngram)         \n",
    "negcounts = build_dict(ntrain, ngram)         \n",
    "\n",
    "dic, r = compute_ratio(poscounts, negcounts)\n",
    "print(\"processing files...\")\n",
    "process_files(ptrain, ntrain, dic, r, \"train-nbsvm.txt\", ngram)\n",
    "process_files(ptest, ntest, dic, r, \"test-nbsvm.txt\", ngram)\n",
    "\n",
    "print(r, dict)\n",
    "trainsvm = os.path.join(liblinear, \"train\") \n",
    "predictsvm = os.path.join(liblinear, \"predict\") \n",
    "os.system(trainsvm + \" -s 0 train-nbsvm.txt model.logreg\")\n",
    "os.system(predictsvm + \" -b 1 test-nbsvm.txt model.logreg \" + out)\n",
    "os.system(\"rm model.logreg train-nbsvm.txt test-nbsvm.txt\")\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
